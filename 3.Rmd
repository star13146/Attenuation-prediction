---
title: "Untitled"
output: html_document
date: "2024-11-21"
---


```{r}
library(randomForest)
library(caret)
library(readr)
library(dplyr)
data <- read_csv("RFLFSODataFull.csv", show_col_types = FALSE)
set.seed(1710063)  # For reproducibility
```
# Split data
```{r}
# Set One: Exclude FSO_Att (column 1)
RFL_data <- data[, -1] 
RFL_data_train_index <- createDataPartition(RFL_data$RFL_Att, p = 0.7, list = FALSE)

# Split the data into training and testing sets
RFL_data_train_set <- RFL_data[RFL_data_train_index, ]
RFL_data_test_set <- RFL_data[-RFL_data_train_index, ]
# Set Two: Exclude RFL_Att (column 2)
FSO_data <- data[, -2] 
FSO_data_train_index <- createDataPartition(FSO_data$FSO_Att, p = 0.7, list = FALSE)

# Split the data into training and testing sets
FSO_data_train_set <- FSO_data[FSO_data_train_index, ]
FSO_data_test_set <- FSO_data[-FSO_data_train_index, ]

```

```{r}
split_train_data_by_synop <- function(train_data, synop_column) {
  subsets <- split(train_data, train_data[[synop_column]]) # Split data by SYNOP codes
  return(subsets)
}

synop_column<- "SYNOPCode"
train_subsets <- split_train_data_by_synop(FSO_data_train_set, synop_column)
test_subsets <- split_train_data_by_synop(FSO_data_test_set, synop_column)
```


# Genearl model training
## FSO
```{r}
target_var <- FSO_data_train_set$FSO_Att
exclude_vars = c("FSO_Att","Visibility", "Time", "WindSpeedMin","TemperatureDifference","Temperature")
train_features <- FSO_data_train_set[, !(colnames(FSO_data_train_set) %in% c(target_var, exclude_vars))]
```

```{r}
# Load necessary libraries
library(randomForest)
library(foreach)
library(doParallel)

# Set up a parallel backend
num_cores <- detectCores() - 1 # Use all cores except one
cl <- makeCluster(num_cores)  # Create cluster
registerDoParallel(cl)         # Register the cluster for parallel backend

# Define the total number of trees and split among cores
total_trees <- 100  # Adjust as needed
trees_per_core <- total_trees / num_cores

# Train the model in parallel
FSO_general_rfmodel <- foreach(ntree = rep(trees_per_core, num_cores), 
                                .combine = randomForest::combine, 
                                .packages = "randomForest") %dopar% {
  randomForest(x = train_features, y = target_var, ntree = ntree)
}

# Stop the parallel cluster
stopCluster(cl)

# Print the model summary
print(FSO_general_rfmodel)
```
## Testing
```{r}
library(foreach)
library(doParallel)
library(randomForest)

# Define the parallel prediction function
parallel_predict <- function(model, newdata, num_cores = NULL) {
  # If num_cores is not specified, use all cores except one
  if (is.null(num_cores)) {
    num_cores <- detectCores() - 1
  }
  
  # Create and register the parallel backend
  cl <- makeCluster(num_cores)
  registerDoParallel(cl)
  
  # Split the newdata into chunks for parallel processing
  chunk_size <- ceiling(nrow(newdata) / num_cores)
  data_chunks <- split(newdata, rep(1:num_cores, each = chunk_size, length.out = nrow(newdata)))
  
  # Perform parallel predictions
  predictions <- foreach(chunk = data_chunks, .combine = c, .packages = "randomForest") %dopar% {
    predict(model, newdata = chunk)
  }
  
  # Stop the parallel backend
  stopCluster(cl)
  
  # Return the combined predictions
  return(predictions)
}

```



```{r}
# Function to test models on test subsets and calculate metrics
test_rf_models <- function(model, test_subsets, target_var, exclude_vars) {
  results <- list() # To store R2 and RMSE for each SYNOP code
  
  for (synop_code in names(test_subsets)) {
    print(synop_code)
    # Get the test subset
    test_data <- test_subsets[[synop_code]]
      
    # Remove excluded variables from the test dataset
    test_features <- test_data[, !(colnames(test_data) %in% c(target_var, exclude_vars))]
    test_target <- test_data[[target_var]]
      
      # Make predictions
    predictions <- parallel_predict(model, newdata = test_features)
      
      # Calculate R2
    ss_total <- sum((test_target - mean(test_target))^2)
    ss_residual <- sum((test_target - predictions)^2)
    r2 <- 1 - (ss_residual / ss_total)
      
      # Calculate RMSE
    rmse <- sqrt(mean((test_target - predictions)^2))
      
      # Store the metrics
    results[[synop_code]] <- list(R2 = r2, RMSE = rmse)
  }
  
  return(results)
}



```

```{r}

exclude_vars = c("Visibility", "Time", "WindSpeedMin","TemperatureDifference","Temperature")

# Test models on test subsets and calculate metrics
metrics_results <- test_rf_models(model = FSO_general_rfmodel, test_subsets = test_subsets, target_var = "FSO_Att", exclude_vars = exclude_vars)

```












## RFL
```{r}
target_var <- RFL_data_train_set$RFL_Att
exclude_vars = c("AbsoluteHumidity", "Time", "Distance","Frequency","VisibilityMax")
train_features <- RFL_data_train_set[, !(colnames(RFL_data_train_set) %in% c(target_var, exclude_vars))]
train_features
target_var
```

```{r}
# Load necessary libraries
library(randomForest)
library(foreach)
library(doParallel)

# Set up a parallel backend
num_cores <- detectCores() - 1 # Use all cores except one
cl <- makeCluster(num_cores)  # Create cluster
registerDoParallel(cl)         # Register the cluster for parallel backend

# Define the total number of trees and split among cores
total_trees <- 100  # Adjust as needed
trees_per_core <- total_trees / num_cores

# Train the model in parallel
RFL_general_rfmodel <- foreach(ntree = rep(trees_per_core, num_cores), 
                                .combine = randomForest::combine, 
                                .packages = "randomForest") %dopar% {
  randomForest(x = train_features, y = target_var, ntree = ntree)
}

# Stop the parallel cluster
stopCluster(cl)

# Print the model summary
print(RFL_general_rfmodel)

```


# Specific model training
# Specific FSO
```{r}
exclude_vars_0 = c("Visibility", "Time", "WindSpeedMin","TemperatureDifference","Temperature","TemperatureMin","WindSpeedMax","VisibilityMax","TemperatureMax","VisibilityMin","ParticulateMin")
exclude_vars_3 = c("Visibility","TemperatureDifference","Temperature","TemperatureMin","VisibilityMax","TemperatureMax","VisibilityMin","Distance")
exclude_vars_4 = c("TemperatureMin","ParticulateMax","Temperature","WindSpeed","Time","Distance")
exclude_vars_5 = c("Distance","Visibility","RelativeHumidity","Time","Temperature","VisibilityMax")
exclude_vars_6 = c("Particulate","Time","WindSpeedMin","RelativeHumidity","Visibility","Temperature","TemperatureDifference")
exclude_vars_7 = c("TemperatureMin","WindSpeedMax","Visibility","Temperature")
exclude_vars_8 = c("VisibilityMin","RelativeHumidity","ParticulateMin","Temperature","AbsoluteHumidity","Time")
```

# Specific RFL
```{r}
exclude_vars_0 = c("Time","AbsoluteHumidity","Visibility","Frequency","WindSpeedMin","AbsoluteHumidityMin")
exclude_vars_3 = c("TemperatureMax","Temperature","RelativeHumidity","Frequency","TemperatureDifference","AbsoluteHumidity")
exclude_vars_4 = c("RainIntensity","Visibility","RelativeHumidity","RainIntensityMin","RainIntensityMax","TemperatureMin")
exclude_vars_5 = c("AbsoluteHumidity","RelativeHumidity","VisibilityMax","WindSpeed")
exclude_vars_6 = c("AbsoluteHumidity","Time","TemperatureDifference","Visibility","Frequency")
exclude_vars_7 = c("AbsoluteHumidity","TemperatureDifference","RelativeHumidity","RainIntensityMin","Time")
exclude_vars_8 = c("RainIntensity","Visibility","RainIntensityMin","TemperatureDifference","VisibilityMin","AbsoluteHumidityMax","RelativeHumidity","Frequency")
```



